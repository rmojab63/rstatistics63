---
title: "مثال ۱۷-۱: توزیع معکوس یک متغیر تصادفی (درک مفهوم با استفاده از کدنویسی)"
author: "رامین مجاب"
output: md_document
---
##  مثال ۱۷-۱: توزیع معکوس یک متغیر تصادفی (درک مفهوم با استفاده از کدنویسی)
<p style='font-size: 0.8em;'><b>نویسنده:</b> <span>رامین مجاب</span></p>

**(صفحهٔ ۴۹۳ کتاب)**

ممکن است در متن قبل، تفاوت مخرج کسرها وقتی از ماتریس   دقت به‌جای ماتریس واریانس استفاده می‌کنیم، توجه شما را جلب کرده باشد.  به‌عبارت دیگر، دو فرمول $\mathbf{S}/(N-p-1)$ و $\mathbf{S}/N$ در متن اشاره شد (اولی برای واریانس و دومی برای معکوس دقت). برای درک این موضوع، توجه کنید که این فرمول‌ها از محاسبهٔ مقدار موردانتظار توزیع ویشارت و معکوس ویشارت به‌دست آمدند.  برای متغیر تصادفی $X$، الزاماً تساوی $\operatorname{E}(X)=1/\operatorname{E}(1/X)$ برقرار نیست؛ یعنی با معکوس‌کردن متغیر تصادفی، مقدار موردانتظار آن تغییر می‌کند. اجازه دهید این موضوع را با استفاده از توزیع کای-دو و معکوس کای-دو (که حالت یک‌متغیره توزیع ویشارت و معکوس ویشارت است) بررسی کنیم. درجهٔ آزادی را در این نمایش ۵ انتخاب می‌کنیم.


``` r
> par <- par(mar = c(2, 2, 2, 2) + 0.1)
> dichisq <- function(x, df) {
+   dgamma(1 / x, shape = df / 2, scale = 1 / 2) / x^2
+ }
> df <- 5
> x <- seq(0.01, 10, length.out = 1000)
> y_chi_squared <- dchisq(x, df)
> y_inv_chi_squared <- dichisq(x, df)
> mean_chi_squared <- df
> mean_inv_chi_squared <- 2 / (df - 2) # valid only for df > 2
> 
> plot(x, y_chi_squared,
+   type = "l", col = "blue", ylim = c(0, max(y_chi_squared, y_inv_chi_squared)),
+   xlab = "x", ylab = "Density"
+ )
> 
> lines(c(mean_chi_squared, mean_chi_squared), c(0, dchisq(mean_chi_squared, df)), col = "blue", lty = 2)
> text(mean_chi_squared, 0.05, paste(round(mean_chi_squared, 2)),
+   pos = 1, col = "blue"
+ )
> lines(x, y_inv_chi_squared, col = "red", lty = 2)
> lines(c(mean_inv_chi_squared, mean_inv_chi_squared), c(0, dichisq(mean_inv_chi_squared, df)), col = "red", lty = 2)
> text(mean_inv_chi_squared, 0.05, paste(round(mean_inv_chi_squared, 2)), pos = 1, col = "red")
> legend("topright",
+   legend = c("کای-دو", "معکوس کای-دو"), fill = c("blue", "red"),
+   lty = c(1, 2)
+ )
```

<img src="/rstatistics63/assets/images/matrix_book_fa/fig_distribution_inverse-1.svg" style="display: block; margin: auto;" />
چگالی توزیع کای-دو را با تابع `dchisq()` محاسبه می‌کنیم. همچنین، ازآنجاکه معکوس کای-دو حالت خاصی از توزیع معکوس گاماست، چگالی آن را با استفاده از کد زیر محاسبه می‌کنیم:

``` r
> dgamma(1 / x, shape = df / 2, scale = 1 / 2) / x^2
```
در این نمایش، `df` درجهٔ آزادی توزیع کای-دو معکوس است. همچنین، بخش `x\^2` از ژاکوبین تبدیل متغیر $y=1/x$ حاصل می‌شود (به یاد  بیاورید که مشتق این تابع برابر با $-1/x^2$ است).

می‌دانیم که مقدار موردانتظار توزیع کای-دو برابر با درجهٔ آزادی است. این نکته در نمودار نیز مشخص است. بااین‌حال، مقدار موردانتظار در توزیع معکوس کای-دو برابر با معکوس درجهٔ آزادی نیست، بلکه برابر با $1/(\nu-2)$ است (مشابه با توزیع معکوس ویشارت وقتی $p=1$ و $\mathbf{S}=1$ است).

به یاد بیاورید که ارتباط بین توزیع متغیر تصادفی $X$ و معکوس آن از طریق تابع `CDF` توضیح داده می‌شود. اگر $P(X\le x)$ را در نظر بگیرید و از تغییر متغیر $Y=1/X$ استفاده کنید (برای سادگی، فرض کنید $X>0$ و پیوسته است)، آنگاه معادل آن برابر با $1-P(X< 1/x)$ به‌دست می‌آید؛ یعنی مساحت دنبالهٔ چپ سری تا $x$ در توزیع $X$ برابر با مساحت دنبالهٔ راست سری از $1/x$ در توزیع $1/X$ است (دربارهٔ مقدار موردانتظار در این مثال صحبت کردیم. با توجه به نکته‌ای که دربارهٔ تابع `CDF` بیان شد، به‌عنوان تمرین، میانهٔ دو توزیع را با یکدیگر مقایسه کنید).

اکنون به بحث تفاوت در مقدار موردانتظار در توزیع ویشارت و معکوس آن بازمی‌گردیم. به یاد بیاورید که در یک پیش‌زمینهٔ بیزین قرار داریم و میانگین تنها یکی از راه‌های خلاصه‌کردن اطلاعات توزیع است. اگر صرفاً بر این معیار تکیه شود، تفاوت‌هایی نظیر آنچه در متن با آن برخورد کردیم به‌وجود می‌آید. ارزش `CDF` اطلاعات کامل‌تری از توزیع دارد و چنین تفاوت‌هایی در استفاده از آن ایجاد نمی‌شود. البته، توجه کنید که اگر $N$ (یعنی درجهٔ آزادی) عدد بزرگی باشد،  ارزش $p-1$ عملاً تفاوت خاصی ایجاد نمی‌کند.

نکتهٔ مهم دیگر (همان‌طور که خواهید دید) به نمونه‌گیری تصادفی از توزیع ویشارت و معکوس آن بازمی‌گردد. نمونه‌گیری از توزیع ویشارت با تابع `rWishart()` امکان‌پذیر است. کد زیر مقدار موردانتظار نمونه‌های این تابع را نشان می‌دهد:

``` r
> S <- matrix(c(2, 3, 3, 5), nrow = 2)
> df <- 100
> 
> samples <- rWishart(10000, df, S)
> sample_mean <- apply(samples, c(1, 2), mean)
> expected_value <- S * df
> 
> abs(sample_mean - expected_value) / expected_value * 100
```

```
#             [,1]        [,2]
# [1,] 0.040289221 0.007500444
# [2,] 0.007500444 0.026921474
```
در خط اول، پارامتر مقیاس توزیع را به‌صورت برون‌زا در ماتریس `S` تعریف کرده‌ایم. این ماتریس باید مثبت معین باشد، زیرا درون تابع `rWishart()` از تجزیهٔ چولسکی استفاده می‌شود. پس از تعریف درجهٔ آزادی، تعداد زیادی نمونهٔ تصادفی استخراج شده و میانگین آن‌ها محاسبه شده است. خط آخر که نتایج آن را مشاهده می‌کنید، درصد خطا در فاصلهٔ بین میانگین نمونه و مقدار موردانتظار است.

اکنون اجازه دهید اشتباه کنیم. در کد زیر، نمونه‌های به‌دست‌آمده را معکوس می‌کنیم و به‌عنوان نمونه‌هایی از توزیع معکوس ویشارت در نظر می‌گیریم:

``` r
> samples_inv <- lapply(
+   1:dim(samples)[3],
+   function(i) solve(samples[, , i])
+ )
> sample_mean <- Reduce("+", samples_inv) / length(samples_inv)
> expected_value <- S / (df - nrow(S) - 1)
> 
> abs(sample_mean - expected_value) / expected_value * 100
```

```
#          [,1]      [,2]
# [1,] 149.9509 199.94891
# [2,] 199.9489  60.03144
```
درصد خطا بین مقدار موردانتظار و میانگین قابل‌پذیرش نیست، زیرا همان‌طور که گفته شد، اشتباه کرده‌ایم.  باید از معکوس ماتریس `S` به‌عنوان پارامتر مقیاس توزیع معکوس ویشارت استفاده کنیم.  این موضوع با مقایسهٔ `pdf`ها مشخص می‌شود.

اکنون به بحث نمونه‌گیری ماتریس واریانس و دقت توجه کنید. در کاربرد، ابتدا تفاضل $\mathbf{y}_i-\boldsymbol{\mu}$ و بنابراین، ماتریس $\mathbf{S}$ محاسبه می‌شود. اگر معکوس این ماتریس را محاسبه کنیم و نمونه‌ای از توزیع ویشارت به‌دست آوریم، عملاً نمونه‌ای از توزیع پسین (شرطی) دقت داریم. حال اگر این نمونه را معکوس کنیم، نمونه‌ای از توزیع (پسین) شرطی واریانس به‌دست می‌آید. اینکه واریانس به یک عملیات معکوس‌کردن بیشتر نیازمند است، الزاماً به این معنا نیست که استفاده از ماتریس دقت می‌تواند کارایی عملیاتی داشته باشد، زیرا نتیجه به چهارچوب بحث بستگی دارد؛ به‌عنوان مثال، اگر بخواهیم نمونهٔ به‌دست‌آمده را مجدداً برای نمونه‌گیری از توزیع نرمال استفاده کنیم، ماتریس دقت را باید به ماتریس واریانس تبدیل کنیم.


<p style='margin-bottom:3cm;'></p><hr/>

- [مثال ۱۶-۳: مدل‌سازی با عوامل فصلی (مدل‌سازی با بستهٔ نرم‌افزاری `dlm`)](matrix_book_fa_example16.3.html)
- [مثال ۱۷-۲: نمونه‌گیری گیبس (تمرین کدنویسی)](matrix_book_fa_example17.2.html)
- [<b>لیست مثال‌ها</b>](matrix_book_fa.html)
