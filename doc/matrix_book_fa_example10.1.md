---
title: "مثال ۱۰-۱: بهینه‌یابی چندمتغیره (معرفی برخی از توابع و فرایندها)"
author: "رامین مجاب"
output: md_document
---
##  مثال ۱۰-۱: بهینه‌یابی چندمتغیره (معرفی برخی از توابع و فرایندها)
<p style='font-size: 0.8em;'><b>نویسنده:</b> <span>رامین مجاب</span></p>

**(صفحهٔ ۳۰۲ کتاب)**

‏**R** ابزارهای قدرتمندی برای بهینه‌یابی دارد. در این مثال، بسته به فروض مختلف دربارهٔ تابع هدف و مسئلهٔ بهینه‌یابی، کدهای مختلفی ارائه و بحث می‌شود. پس، بحث را به موارد زیر می‌شکنیم:
 
### بهینه‌یابی با استفاده از حل تحلیلی بردار گرادیان و ماتریس هشین
در مباحثی که در فصل «بهینه‌یابی چندمتغیره» (صفحهٔ ۲۹۳ در کتاب) مطرح شد، مشتق‌پذیری تابع هدف یکی از فروض اصلی بود. بحث را از یک مسئلهٔ بهینه‌یابی آغاز می‌کنیم که مشتق مرتبهٔ اول و دوم برای آن وجود دارد و از آن اطلاع داریم. در مثالی که در ادامه می‌آید، تابع چندمتغیرهٔ زیر را به‌عنوان تابع هدف استفاده می‌کنیم:
$$
\operatorname{f}(\mathbf{x};\mathbf{A},\mathbf{a})=\mathbf{x}'\mathbf{A}\mathbf{x} +\mathbf{a}'\mathbf{x}+c
$$
کد زیر را مطالعه کنید:

``` r
> func <- function(x) {
+   return(t(x) %*% A %*% x + t(b) %*% x + c)
+ }
> grad <- function(x) {
+   return(2 * A %*% x + b)
+ }
> hessian <- function(x) {
+   return(2 * A)
+ }
> 
> A <- matrix(c(2, -1, -1, 2), nrow = 2)
> b <- c(-1, -1)
> c <- 0
> 
> result <- nlminb(
+   start = c(0, 0), objective = func,
+   gradient = grad, hessian = hessian
+ )
> print(result$par)
```

```
# [1] 0.5 0.5
```
برای تابع هدف، توابع گرادیان و هشین را می‌دانیم و نیز می‌خواهیم از این اطلاعات استفاده کنیم. پس، تابع `nlminb()` انتخاب مناسبی است. الگوریتم داخلی این تابع (شبیه به) روش نیوتون است. به چند نکته نیز توجه کنید:

- هدف حداقل‌کردن تابع  است. برای یافتن حداکثر یک تابع، قرینهٔ تابع را حداقل می‌کنیم. به‌عنوان تمرین، تابع مثال قبل را حداکثر کنید.
- ورودی توابع باید بردار باشد. تابع هدف باید اسکالر بازگرداند. تابع گرادیان و تابع هشین نیز باید به‌ترتیب یک بردار و یک ماتریس بازگردانند. نیاز به توضیح ندارد که اندازه‌ها باید سازگار با تعداد متغیرها باشد. رعایت‌نکردن این‌گونه قواعد به خطا می‌انجامد.
- ارزش تابع هدف در نقطهٔ بهینه را با دستور  `func(result$par)` محاسبه کنید. 
- در کاربردهایی که تابع هدف به این اندازه خوش‌رفتار نیست و نقاط بحرانی محلی زیادی وجود دارد، نقش نقطهٔ اولیه حیاتی است. معمولاً باید راه‌حلی منطقی (و بر پایهٔ نظریه) برای یافتن این نقاط اولیه بیابید.
- در کد فوق، ضرایب ثابت را بیرون از توابع تعریف کردیم. معمولاً توابع بهینه‌یابی از طریق ورودی «`...`»، امکان ارسال اطلاعات اضافی (نظیر داده‌ها و ضرایب ثابت) را فراهم می‌کنند.
- ورودی‌های تابع اجازه می‌دهند که یک مسئله کراندار (یا bounded) تعریف شود؛ هرچند این متفاوت با چیزی است که دربارهٔ بهینه‌یابی با محدودیت مطرح کردیم. در اینجا، دامنه به‌گونه‌ای ابتدایی‌تر محدود می‌شود.


### بهینه‌یابی بدون حل تحلیلی ماتریس هشین
 فرض کنید نمی‌توانیم یا نمی‌خواهیم از فرمول تابع هشین استفاده کنیم. الگوریتم‌های شبه‌نیوتون همچنان می‌توانند نقاط بهینه را بیابند. مثال زیر را در ادامهٔ مثال قبل در نظر بگیرید:

``` r
> optim(
+   par = c(0, 0), fn = func, gr = grad, hessian = TRUE,
+   method = "BFGS"
+ )$par
```

```
# [1] 0.5 0.5
```
در میان گزینه‌هایی که وجود دارد، از تابع `optim()` استفاده کردیم. نکاتی که پیش‌تر عنوان شد، همچنان برقرارند.  توجه کنید که در این تابع، ورودی `hessian`  کاربردی متفاوت دارد. همچنین، توجه کنید که فراهم‌نکردن ماتریس هشین به این معنی نیست که چنین ماتریسی توسط الگوریتم درونی محاسبه نمی‌شود.  

### بهینه‌یابی بدون حل تحلیلی بردار گرادیان و ماتریس هشین
ممکن است در فرایند بهینه‌یابی، بردار گرادیان نیز وجود نداشته باشد. مثال زیر را ملاحظه کنید: 

``` r
> optim(
+   par = c(0, 0), fn = func, hessian = TRUE,
+   method = "BFGS"
+ )$par
```

```
# [1] 0.5 0.5
```
اگر تابع خوش‌رفتار نباشد،   بدون ارائهٔ بردار گرادیان، مشکلاتی محتمل است؛ مثلاً، دقت از دست می‌رود یا سرعت محاسبات کاهش می‌یابد.

### بهینه‌یابی بدون مشتق‌گیری
روش‌های شبه‌نیوتون برای بهینه‌یابی از اطلاعات گرادیان یا هشین (حال، حل تحلیلی یا عددی آن‌ها) استفاده می‌کنند. همهٔ الگوریتم‌ها این‌گونه نیستند. مثال زیر را ملاحظه کنید:

``` r
> func <- function(x) {
+   return(abs(sin(x[1]) + cos(x[2])))
+ }
> 
> optim(par = c(0, 0), fn = func, method = "Nelder-Mead")$par
```

```
# [1] -0.8126699  0.7581265
```

``` r
> optim(par = c(3, 3), fn = func, method = "Nelder-Mead")$par
```

```
# [1] 2.072060 3.642856
```

تابع هدف، حداقل از این نظر که در همهٔ نقاط مشتق‌پذیر نیست، پیچیده است. پس، اگر بخواهید تابع گرادیان را همانند قبل بنویسید، در بعضی از نقاط باید برداری از `NA` بازگردانید و این می‌تواند فرایند بهینه‌یابی را مختل کند. البته، این بدان معنا نیست که نمی‌توانید از یک روش شبه‌نیوتون استفاده کنید، اما اینکه الگوریتم عددی چگونه عمل می‌کند، باید بررسی شود.  نتیجه این کد را ببینید:

``` r
> optim(par = c(3, 3), fn = func, method = "BFGS")$par
```

```
# [1] 1.843613 2.868776
```

پس در این مورد خاص، نتیجهٔ دو روش متفاوت است. بدون بررسی بیشتر و با توجه به وضعیت مشتق‌پذیری تابع و همچنین بدون تغییر دیگر ورودی‌ها (مثلاً شروط همگرایی و غیره)، بهتر است نتیجهٔ روش `Nelder-Mead` استفاده شود.

### بهینه‌یابی با محدودیت
 ‏**R** توابع دیگری برای انجام بهینه‌یابی با محدودیت‌های تساوی یا نامساوی دارد. جست‌وجو و بررسی آن‌ها  به‌عنوان تمرین، به خواننده واگذار می‌شود.
 

در [مثال ۱۲-۳](matrix_book_fa_example12.3)، مثال کامل‌تری برای بهینه‌یابی (در قالب مسئلهٔ حداکثر درست‌نمایی) مطرح می‌شود.



<p style='margin-bottom:3cm;'></p><hr/>

- [مثال ۱-۵: افراز ماتریس‌ها (ارزش‌گذاری و ارزش‌گیری از زیرمجموعه‌ای از درایه‌های یک ماتریس)](matrix_book_fa_example1.5.html)
- [مثال ۱۱-۱: مجموعهٔ نمونه (معرفی  `data.frame`)](matrix_book_fa_example11.1.html)
- [<b>لیست مثال‌ها</b>](matrix_book_fa.html)
